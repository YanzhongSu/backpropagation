<!DOCTYPE html>
<html>
  <head>
	<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
	<meta http-equiv="X-UA-Compatible" content="chrome=1,IE=edge" />
	<title>Presentation-webApp</title>
	<style>
		html {
			height:100%;
		}
		body {
			background-color:#FFFFFF;
			margin:0;
			height:100%;
		}
	</style>
	<!-- copy these lines to your document head: -->

	<meta name="viewport" content="user-scalable=yes, width=1024" />

	<!-- end copy -->
  </head>
  <body>
	<!-- copy these lines to your document: -->

	<div id="presentationwebapp_hype_container" style="margin:auto;position:relative;width:1024px;height:768px;overflow:hidden;" aria-live="polite">
		<script type="text/javascript" charset="utf-8" src="Presentation-webApp.hyperesources/presentationwebapp_hype_generated_script.js?18008"></script>
	</div>

	<!-- end copy -->
	


	<!-- text content for search engines: -->

	<div style="display:none">

		<div>Impact 
</div>
		<div>Introduction

Live Demo


</div>
		<div>Learning representaions by 
back-propagation errors
</div>
		<div></div>
		<div>Artificial Intelligence</div>
		<div>Desired Outputs</div>
		<div>1.Automatic computer
2.Language understanding
3.Usage of neuron nets
4.Computational efficiency
5.Self-improvement
6.Abstractions
7.Creativity EndFragment</div>
		<div>Neuron fires output signal if the sum of input is above threshold
</div>
		<div>Represent the strength of
the connection between two cells.
</div>
		<div>Synaptic weight</div>
		<div>Threshold for activation
</div>
		<div>Cumulative affect
</div>
		<div>Nerons</div>
		<div>Learning step by step
</div>
		<div>Inputs</div>
		<div>Neuron</div>
		<div>
</div>
		<div>w3</div>
		<div>Synaptic weights
</div>
		<div>or</div>
		<div>x1 * w1 + x2 * w2 + x3 * w3


EndFragment</div>
		<div>X1</div>
		<div>X2</div>
		<div>w1</div>
		<div>Output</div>
		<div>X3</div>
		<div>w2</div>
		<div>Threshold</div>
		<div>1
</div>
		<div>"Perfection"
</div>
		<div>b</div>
		<div>Linear regression</div>
		<div>Linear equation (only one input)</div>
		<div>New activation functions
</div>
		<div>Previous model can not deal with
non-linear problem
</div>
		<div>Limitations & Improvement</div>
		<div>We built multi-layered neural networks:

    Adding "hidden" neurons between    inputs and outputs.

     Let these "nodes" feeding each other.
</div>
		<div>The activation function for threshold is also
 linear seperation</div>
		<div>X2
</div>
		<div>input layer       hidden layer*n        output layer
</div>
		<div>Model</div>
		<div>X1
</div>
		<div>Sample</div>
		<div>The most important part : self-training the weights</div>
		<div>Impacts</div>
		<div>→ Appreciated by Machine Learning Community

→ First method show neural network could learn good internal representations

→ Allow neural network applied to a much wider field

→ After 2010, becomes more popular and powerful with GPU — deep learning
</div>

	</div>

	<!-- end text content: -->

  </body>
</html>
